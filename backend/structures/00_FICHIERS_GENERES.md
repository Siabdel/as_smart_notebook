# ğŸ“¦ Smart-Notebook - Fichiers GÃ©nÃ©rÃ©s

## ğŸ¯ RÃ©capitulatif Complet

Tous les fichiers essentiels pour dÃ©marrer votre clone de NotebookLM ont Ã©tÃ© gÃ©nÃ©rÃ©s avec succÃ¨s !

---

## ğŸ“‚ Liste des Fichiers

### ğŸ”§ Configuration & Installation

#### 1. **requirements.txt** 
- Toutes les dÃ©pendances Python nÃ©cessaires
- Django 5, DRF, Celery, pgvector, OpenAI SDK, etc.
- **Emplacement**: Racine du projet backend

#### 2. **env_example.txt** (Ã  renommer en `.env`)
- Variables d'environnement complÃ¨tes
- ClÃ©s API, configuration DB, Ollama, OpenRouter
- **Emplacement**: Racine du projet backend
- **Action requise**: Renommer en `.env` et remplir vos vraies valeurs

#### 3. **init_db.sh**
- Script Bash d'initialisation PostgreSQL + pgvector
- CrÃ©e la DB, l'utilisateur, active l'extension
- **Emplacement**: `scripts/init_db.sh`
- **Usage**: `chmod +x init_db.sh && ./init_db.sh`

#### 4. **django_settings.py**
- Configuration Django complÃ¨te (settings.py)
- PostgreSQL, Celery, CORS, Logging, etc.
- **Emplacement**: `config/settings.py`

#### 5. **celery_config.py**
- Configuration Celery avec queues et tÃ¢ches pÃ©riodiques
- **Emplacement**: `config/celery.py`

---

### ğŸ—ï¸ ModÃ¨les Django

#### 6. **documents_models.py**
- `SourceDocument`: Documents uploadÃ©s (PDFs, TXT)
- `DocumentChunk`: Fragments vectorisÃ©s avec pgvector
- `QueryLog`: Historique des questions RAG
- **Emplacement**: `apps/documents/models.py`

---

### ğŸ¤– Intelligence Artificielle

#### 7. **ai_router.py**
- Classe `AIRouter` qui gÃ¨re Ollama (local) + OpenRouter (cloud)
- MÃ©thodes: `get_embedding()`, `chat_completion()`
- Gestion d'erreurs robuste
- **Emplacement**: `apps/core/ai_router.py`

---

### âš™ï¸ TÃ¢ches Asynchrones

#### 8. **tasks.py**
- TÃ¢ches Celery pour ingestion de documents
- `process_document_ingestion()`: extraction, chunking, embeddings
- `cleanup_failed_documents()`: maintenance pÃ©riodique
- **Emplacement**: `apps/documents/tasks.py`

---

### ğŸŒ API REST

#### 9. **views.py**
- `AskDocumentView`: Endpoint RAG principal
- `DocumentStatsView`: Statistiques utilisateur
- `RateFeedbackView`: Notation des rÃ©ponses
- **Emplacement**: `apps/rag/views.py`

#### 10. **serializers.py**
- Serializers DRF pour upload, validation, RAG
- `DocumentUploadSerializer`, `AskQuestionSerializer`, etc.
- **Emplacement**: `apps/documents/serializers.py`

---

### ğŸ§ª Tests & Utilitaires

#### 11. **test_ollama.py**
- Script de test pour vÃ©rifier Ollama
- Teste la connexion, les embeddings, la similaritÃ©
- **Emplacement**: `scripts/test_ollama.py`
- **Usage**: `python scripts/test_ollama.py`

---

### ğŸ“š Documentation

#### 12. **README_BACKEND.md**
- Documentation complÃ¨te du backend
- Installation, configuration, architecture, API
- DÃ©pannage et bonnes pratiques
- **Emplacement**: `README.md` (racine backend)

---

## ğŸš€ Guide de DÃ©marrage Rapide

### 1ï¸âƒ£ Installer les prÃ©requis
```bash
# PostgreSQL
sudo apt-get install postgresql postgresql-contrib

# Redis
sudo apt-get install redis-server

# Ollama
curl -fsSL https://ollama.com/install.sh | sh
ollama pull nomic-embed-text

# Tesseract (optionnel)
sudo apt-get install tesseract-ocr tesseract-ocr-fra
```

### 2ï¸âƒ£ Initialiser la base de donnÃ©es
```bash
chmod +x scripts/init_db.sh
./scripts/init_db.sh
```

### 3ï¸âƒ£ Installer les dÃ©pendances Python
```bash
python3 -m venv venv
source venv/bin/activate
pip install -r requirements.txt
```

### 4ï¸âƒ£ Configurer l'environnement
```bash
cp env_example.txt .env
nano .env  # Remplir vos valeurs
```

### 5ï¸âƒ£ Lancer les migrations
```bash
python manage.py makemigrations
python manage.py migrate
python manage.py createsuperuser
```

### 6ï¸âƒ£ DÃ©marrer les services
```bash
# Terminal 1: Django
python manage.py runserver

# Terminal 2: Celery Worker
celery -A config worker --loglevel=info

# Terminal 3: Celery Beat
celery -A config beat --loglevel=info
```

---

## ğŸ“‹ Structure RecommandÃ©e du Projet

```
backend/
â”œâ”€â”€ manage.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                          # â† Ã€ crÃ©er depuis env_example.txt
â”œâ”€â”€ README.md                      # â† README_BACKEND.md
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ settings.py                # â† django_settings.py
â”‚   â”œâ”€â”€ urls.py
â”‚   â”œâ”€â”€ wsgi.py
â”‚   â”œâ”€â”€ asgi.py
â”‚   â””â”€â”€ celery.py                  # â† celery_config.py
â”‚
â”œâ”€â”€ apps/
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ ai_router.py           # â† ai_router.py
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ documents/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ models.py              # â† documents_models.py
â”‚   â”‚   â”œâ”€â”€ serializers.py         # â† serializers.py
â”‚   â”‚   â”œâ”€â”€ views.py               # â† (crÃ©ation views upload)
â”‚   â”‚   â”œâ”€â”€ urls.py
â”‚   â”‚   â””â”€â”€ tasks.py               # â† tasks.py
â”‚   â”‚
â”‚   â”œâ”€â”€ rag/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ views.py               # â† views.py
â”‚   â”‚   â”œâ”€â”€ serializers.py         # â† (partie RAG de serializers.py)
â”‚   â”‚   â””â”€â”€ urls.py
â”‚   â”‚
â”‚   â””â”€â”€ podcasts/
â”‚       â””â”€â”€ ...
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ init_db.sh                 # â† init_db.sh
â”‚   â””â”€â”€ test_ollama.py             # â† test_ollama.py
â”‚
â”œâ”€â”€ media/
â”‚   â”œâ”€â”€ documents/
â”‚   â””â”€â”€ podcasts/
â”‚
â””â”€â”€ logs/
    â”œâ”€â”€ django.log
    â””â”€â”€ celery.log
```

---

## âœ… Checklist de VÃ©rification

- [ ] PostgreSQL installÃ© et configurÃ©
- [ ] pgvector installÃ© via `init_db.sh`
- [ ] Redis dÃ©marrÃ© (`redis-cli ping` â†’ PONG)
- [ ] Ollama installÃ© et modÃ¨le tÃ©lÃ©chargÃ© (`ollama list`)
- [ ] Variables `.env` configurÃ©es
- [ ] Migrations Django exÃ©cutÃ©es
- [ ] Superuser crÃ©Ã©
- [ ] Test Ollama rÃ©ussi (`python scripts/test_ollama.py`)
- [ ] Django dÃ©marre sans erreur
- [ ] Celery worker connectÃ©

---

## ğŸ“ Concepts ClÃ©s

### Architecture Hybride IA
- **Local (Ollama)**: Embeddings uniquement (Ã©conomise les coÃ»ts API)
- **Cloud (OpenRouter)**: GÃ©nÃ©ration de texte (meilleure qualitÃ©)

### Workflow RAG
1. Upload PDF â†’ Extraction texte â†’ Chunking
2. GÃ©nÃ©ration embeddings (Ollama) â†’ Stockage pgvector
3. Question utilisateur â†’ Vectorisation â†’ Recherche similaritÃ©
4. Contexte + Question â†’ LLM (OpenRouter) â†’ RÃ©ponse citÃ©e

### Technologies Critiques
- **pgvector**: Extension PostgreSQL pour recherche vectorielle L2
- **Celery**: Traitement asynchrone (ingestion longue durÃ©e)
- **Redis**: Message broker pour Celery
- **Ollama**: LLM local pour embeddings (RTX 3060 compatible)

---

## ğŸ†˜ Besoin d'Aide ?

### ProblÃ¨mes Courants

**Ollama ne dÃ©marre pas**
```bash
sudo systemctl status ollama
sudo systemctl restart ollama
```

**pgvector non trouvÃ©**
```bash
sudo -u postgres psql -d smartnotebook -c "CREATE EXTENSION vector;"
```

**Celery ne trouve pas les tÃ¢ches**
```bash
# VÃ©rifier que __init__.py existe dans apps/documents/
# Relancer avec: celery -A config worker --loglevel=debug
```

---

## ğŸ“ Ressources Additionnelles

- **Ollama Docs**: https://ollama.ai/docs
- **pgvector Repo**: https://github.com/pgvector/pgvector
- **OpenRouter API**: https://openrouter.ai/docs
- **Celery Docs**: https://docs.celeryq.dev
- **Django Docs**: https://docs.djangoproject.com

---

## ğŸ‰ FÃ©licitations !

Vous avez maintenant tous les fichiers nÃ©cessaires pour construire votre clone de NotebookLM. 

**Prochaines Ã©tapes suggÃ©rÃ©es**:
1. Installer et tester le backend
2. CrÃ©er le frontend Vue.js 3
3. IntÃ©grer la gÃ©nÃ©ration de podcasts (edge-tts)
4. DÃ©ployer en production

Bon dÃ©veloppement ! ğŸš€
